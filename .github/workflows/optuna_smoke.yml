name: Optuna Smoke Test

on:
  push:
    branches: [ main, develop, release/* ]
  pull_request:
    branches: [ main, develop ]

jobs:
  optuna-smoke-test:
    runs-on: ubuntu-latest
    timeout-minutes: 3  # Speed guard - max 3 minutes
    
    strategy:
      matrix:
        python-version: ['3.9', '3.11']
        test-mode: ['native']
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        # Install optional optuna dependencies
        pip install optuna optuna-dashboard
        
    - name: Create test directories
      run: |
        mkdir -p studies
        mkdir -p factors
        mkdir -p exports_ci
        
    - name: Run Optuna smoke test
      env:
        TELEGRAM_DRY_RUN: 'true'  # Disable actual Telegram notifications
        PYTHONPATH: '.'
      run: |
        echo "üß™ Running Optuna optimization smoke test..."
        
        # Initialize study first
        python -c "
        from optimize.opt_factor_weights import FactorWeightOptimizer
        import os
        os.makedirs('studies', exist_ok=True)
        optimizer = FactorWeightOptimizer('studies/smoke_test.db')
        study = optimizer.create_enhanced_study('smoke_test_study')
        print(f'‚úÖ Study initialized: {study.study_name}')
        "
        
        # Run small optimization batch
        python mech_exo/cli.py optuna-run \
          --n-trials 5 \
          --n-jobs 2 \
          --study-name smoke_test_study \
          --study-file studies/smoke_test.db \
          --no-stage \
          --no-notify-progress
        
    - name: Verify YAML export exists
      run: |
        echo "üîç Checking for exported YAML file..."
        
        # Find the most recent factors YAML file
        YAML_FILE=$(find factors/ -name "factors_opt_*.yml" -type f | head -1)
        
        if [ -z "$YAML_FILE" ]; then
          echo "‚ùå No YAML file found in factors/ directory"
          ls -la factors/
          exit 1
        fi
        
        echo "‚úÖ Found YAML file: $YAML_FILE"
        
        # Verify YAML structure and content
        python -c "
        import yaml
        import sys
        
        yaml_file = '$YAML_FILE'
        print(f'üìÑ Analyzing YAML file: {yaml_file}')
        
        with open(yaml_file, 'r') as f:
            data = yaml.safe_load(f)
        
        # Check required sections
        required_sections = ['metadata', 'factors', 'hyperparameters']
        for section in required_sections:
            if section not in data:
                print(f'‚ùå Missing required section: {section}')
                sys.exit(1)
        
        # Check factor count
        factor_count = 0
        for category in ['fundamental', 'technical', 'sentiment']:
            if category in data['factors']:
                factor_count += len(data['factors'][category])
        
        print(f'üìä Factor sections found: {list(data[\"factors\"].keys())}')
        print(f'üìä Total factors: {factor_count}')
        print(f'üìä Hyperparameters: {len(data[\"hyperparameters\"])}')
        print(f'üìä Optimization method: {data[\"metadata\"].get(\"optimization_method\", \"unknown\")}')
        
        # Verify minimum factor count (should be at least 5 factors)
        if factor_count < 5:
            print(f'‚ùå Insufficient factors: {factor_count} < 5')
            sys.exit(1)
        
        # Verify essential metadata
        metadata = data['metadata']
        required_metadata = ['created_at', 'optimization_method', 'best_sharpe_ratio', 'total_trials']
        for field in required_metadata:
            if field not in metadata:
                print(f'‚ùå Missing metadata field: {field}')
                sys.exit(1)
        
        print(f'‚úÖ YAML validation passed: {factor_count} factors, {len(data[\"hyperparameters\"])} hyperparameters')
        print(f'‚úÖ Best Sharpe: {metadata[\"best_sharpe_ratio\"]}')
        print(f'‚úÖ Total trials: {metadata[\"total_trials\"]}')
        "
        
    - name: Test export functionality
      env:
        PYTHONPATH: '.'
      run: |
        echo "üì¶ Testing data export functionality..."
        
        # Test export with small dataset (if data exists)
        python mech_exo/cli.py export \
          --table optuna_trials \
          --range last7d \
          --fmt csv \
          --output-dir exports_ci \
          --verbose || echo "‚ö†Ô∏è Export test skipped (no data)"
        
        # List exported files
        echo "üìÅ Exported files:"
        ls -la exports_ci/ || echo "No exports directory"
        
    - name: Upload optimization artifacts
      uses: actions/upload-artifact@v3
      if: always()  # Upload even if tests fail
      with:
        name: optuna-smoke-artifacts-py${{ matrix.python-version }}
        path: |
          factors/factors_opt_*.yml
          studies/smoke_test.db
          exports_ci/*.csv
        retention-days: 3
        
    - name: Test summary
      if: always()
      run: |
        echo ""
        echo "üéØ Optuna Smoke Test Summary"
        echo "============================="
        echo "‚úÖ Python ${{ matrix.python-version }}: Optuna optimization pipeline tested"
        echo "‚úÖ Study creation and trial execution verified"
        echo "‚úÖ YAML export structure and content validated"
        echo "‚úÖ Factor count and metadata requirements met"
        echo ""
        echo "üìä Artifacts uploaded for manual inspection"
        echo "üöÄ Optuna integration ready for production use!"
        
  # Docker-based optimization test
  optuna-docker-test:
    runs-on: ubuntu-latest
    timeout-minutes: 10  # Docker needs more time for build
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Create test directories
      run: |
        mkdir -p studies factors exports_ci
        
    - name: Build Optuna Docker image
      run: |
        echo "üê≥ Building Docker image for Optuna optimization..."
        docker build -f Dockerfile.optuna -t mech-exo-optuna:test .
        
    - name: Run Docker-based optimization
      env:
        TELEGRAM_DRY_RUN: 'true'
      run: |
        echo "üî¨ Running Docker-based Optuna optimization..."
        
        # Create minimal docker-compose override for testing
        cat > docker-compose.test.yml << EOF
        version: '3.8'
        services:
          optuna-runner:
            build:
              context: .
              dockerfile: Dockerfile.optuna
            volumes:
              - ./studies:/app/studies
              - ./factors:/app/factors
            environment:
              - TELEGRAM_DRY_RUN=true
              - PYTHONPATH=/app
            command: >
              sh -c "
                echo 'üî¨ Docker optimization test starting...' &&
                python -m mech_exo.cli optuna-run 
                  --n-trials 3 
                  --n-jobs 1 
                  --study-name docker_test_study 
                  --study-file studies/docker_test.db 
                  --no-stage 
                  --progress-interval 1
              "
        EOF
        
        # Run optimization in Docker
        docker compose -f docker-compose.test.yml up --build --abort-on-container-exit
        
    - name: Verify Docker optimization results
      run: |
        echo "üîç Verifying Docker optimization results..."
        
        # Check if study database was created
        if [ -f "studies/docker_test.db" ]; then
          echo "‚úÖ Study database created: studies/docker_test.db"
          
          # Check database contents
          docker run --rm -v $(pwd)/studies:/studies sqlite:3.40 \
            sqlite3 /studies/docker_test.db \
            "SELECT 'Trials: ' || COUNT(*) FROM trials; SELECT 'Study: ' || study_name FROM studies LIMIT 1;"
        else
          echo "‚ùå Study database not found"
          exit 1
        fi
        
        # Check for YAML exports
        YAML_FILES=$(find factors/ -name "factors_opt_*.yml" -type f | wc -l)
        echo "üìÑ YAML files found: $YAML_FILES"
        
        if [ "$YAML_FILES" -gt 0 ]; then
          echo "‚úÖ Factor export files created"
          ls -la factors/factors_opt_*.yml | head -3
        else
          echo "‚ùå No factor export files found"
          exit 1
        fi
        
    - name: Upload Docker test artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: docker-optuna-test-artifacts
        path: |
          studies/docker_test.db
          factors/factors_opt_*.yml
          docker-compose.test.yml
        retention-days: 3
        
    - name: Docker test summary
      if: always()
      run: |
        echo ""
        echo "üê≥ Docker Optuna Test Summary"
        echo "=============================="
        echo "‚úÖ Docker image build successful"
        echo "‚úÖ Container-based optimization tested"
        echo "‚úÖ Study database and YAML exports verified"
        echo "‚úÖ Docker integration ready for production"
        echo ""
        echo "üìä Artifacts uploaded for inspection"