{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mech-Exo Scoring System Exploration\n",
    "\n",
    "This notebook explores the factor-based scoring system for ranking investment ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Mech-Exo imports\n",
    "from mech_exo.scoring import IdeaScorer\n",
    "from mech_exo.datasource import DataStorage, OHLCDownloader, FundamentalFetcher\n",
    "from mech_exo.utils import ConfigManager\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìä Mech-Exo Scoring Exploration Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Scoring System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scorer\n",
    "try:\n",
    "    scorer = IdeaScorer()\n",
    "    print(f\"‚úÖ Scorer initialized with {len(scorer.factors)} factors\")\n",
    "    \n",
    "    # Display factor information\n",
    "    factor_info = []\n",
    "    for name, factor in scorer.factors.items():\n",
    "        factor_info.append({\n",
    "            'Factor': name,\n",
    "            'Weight': factor.weight,\n",
    "            'Direction': factor.direction\n",
    "        })\n",
    "    \n",
    "    factor_df = pd.DataFrame(factor_info)\n",
    "    print(\"\\nüìã Factor Configuration:\")\n",
    "    display(factor_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize scorer: {e}\")\n",
    "    scorer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check Available Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scorer:\n",
    "    storage = scorer.storage\n",
    "    \n",
    "    # Check universe\n",
    "    universe = storage.get_universe()\n",
    "    print(f\"üåç Universe contains {len(universe)} symbols\")\n",
    "    \n",
    "    if not universe.empty:\n",
    "        print(\"\\nUniverse symbols:\")\n",
    "        display(universe.head(10))\n",
    "        \n",
    "        # Check data availability\n",
    "        sample_symbols = universe['symbol'].head(5).tolist()\n",
    "        \n",
    "        ohlc_data = storage.get_ohlc_data(sample_symbols)\n",
    "        fundamental_data = storage.get_fundamental_data(sample_symbols)\n",
    "        news_data = storage.get_news_data(sample_symbols, days_back=7)\n",
    "        \n",
    "        print(f\"\\nüìà OHLC records: {len(ohlc_data)}\")\n",
    "        print(f\"üìä Fundamental records: {len(fundamental_data)}\")\n",
    "        print(f\"üì∞ News articles: {len(news_data)}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No symbols in universe - run data pipeline first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Scoring Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scorer and not universe.empty:\n",
    "    try:\n",
    "        # Get sample symbols for scoring\n",
    "        sample_symbols = universe['symbol'].head(10).tolist()\n",
    "        print(f\"üéØ Scoring {len(sample_symbols)} symbols: {sample_symbols}\")\n",
    "        \n",
    "        # Run scoring\n",
    "        ranking = scorer.score(sample_symbols)\n",
    "        \n",
    "        if not ranking.empty:\n",
    "            print(f\"‚úÖ Successfully scored {len(ranking)} symbols\")\n",
    "            \n",
    "            # Display top results\n",
    "            print(\"\\nüèÜ Top Investment Ideas:\")\n",
    "            display(ranking.head())\n",
    "            \n",
    "            # Save ranking\n",
    "            scorer.save_ranking(ranking, \"data/sample_ranking.csv\")\n",
    "            print(\"üíæ Ranking saved to data/sample_ranking.csv\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå No ranking results generated\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Scoring failed: {e}\")\n",
    "        ranking = pd.DataFrame()\nelse:\n",
    "    print(\"‚ö†Ô∏è Cannot run scoring - initialize scorer and data first\")\n",
    "    ranking = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Scoring Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ranking.empty:\n",
    "    # Score distribution\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(ranking['composite_score'], bins=10, alpha=0.7, edgecolor='black')\n",
    "    plt.title('Distribution of Composite Scores')\n",
    "    plt.xlabel('Composite Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(ranking['rank'], ranking['composite_score'], alpha=0.7)\n",
    "    plt.title('Rank vs Composite Score')\n",
    "    plt.xlabel('Rank')\n",
    "    plt.ylabel('Composite Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nüìà Scoring Summary:\")\n",
    "    print(f\"Mean Score: {ranking['composite_score'].mean():.3f}\")\n",
    "    print(f\"Std Score: {ranking['composite_score'].std():.3f}\")\n",
    "    print(f\"Min Score: {ranking['composite_score'].min():.3f}\")\n",
    "    print(f\"Max Score: {ranking['composite_score'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ranking.empty and scorer:\n",
    "    # Analyze factor contributions\n",
    "    print(\"üîç Factor Weight Analysis:\")\n",
    "    \n",
    "    factor_weights = []\n",
    "    for name, factor in scorer.factors.items():\n",
    "        factor_weights.append({\n",
    "            'Factor': name.replace('_', ' ').title(),\n",
    "            'Weight': factor.weight,\n",
    "            'Direction': factor.direction\n",
    "        })\n",
    "    \n",
    "    weight_df = pd.DataFrame(factor_weights)\n",
    "    weight_df = weight_df.sort_values('Weight', ascending=False)\n",
    "    \n",
    "    # Plot factor weights\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(range(len(weight_df)), weight_df['Weight'], alpha=0.7)\n",
    "    plt.title('Factor Weights in Scoring Model')\n",
    "    plt.xlabel('Factors')\n",
    "    plt.ylabel('Weight (%)')\n",
    "    plt.xticks(range(len(weight_df)), weight_df['Factor'], rotation=45, ha='right')\n",
    "    \n",
    "    # Color bars by direction\n",
    "    colors = {'higher_better': 'green', 'lower_better': 'red', 'mean_revert': 'blue'}\n",
    "    for i, direction in enumerate(weight_df['Direction']):\n",
    "        bars[i].set_color(colors.get(direction, 'gray'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    display(weight_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Different Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scorer and not universe.empty:\n",
    "    # Test with different symbol sets\n",
    "    test_scenarios = {\n",
    "        'Large Cap ETFs': ['SPY', 'QQQ', 'IWM'],\n",
    "        'Tech Stocks': ['AAPL', 'MSFT', 'GOOGL'],\n",
    "        'International': ['FXI', 'EEM', 'VEA']\n",
    "    }\n",
    "    \n",
    "    scenario_results = {}\n",
    "    \n",
    "    for scenario_name, test_symbols in test_scenarios.items():\n",
    "        # Filter to symbols that exist in universe\n",
    "        available_symbols = [s for s in test_symbols if s in universe['symbol'].values]\n",
    "        \n",
    "        if available_symbols:\n",
    "            try:\n",
    "                scenario_ranking = scorer.score(available_symbols)\n",
    "                if not scenario_ranking.empty:\n",
    "                    scenario_results[scenario_name] = scenario_ranking\n",
    "                    print(f\"‚úÖ {scenario_name}: Scored {len(scenario_ranking)} symbols\")\n",
    "                else:\n",
    "                    print(f\"‚ùå {scenario_name}: No results\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå {scenario_name}: Failed - {e}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {scenario_name}: No symbols available in universe\")\n",
    "    \n",
    "    # Display scenario results\n",
    "    if scenario_results:\n",
    "        print(\"\\nüé≠ Scenario Analysis Results:\")\n",
    "        for scenario_name, results in scenario_results.items():\n",
    "            print(f\"\\n{scenario_name}:\")\n",
    "            display(results[['rank', 'symbol', 'composite_score']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scorer:\n",
    "    # Check data completeness for scoring factors\n",
    "    storage = scorer.storage\n",
    "    \n",
    "    # Get sample of fundamental data\n",
    "    sample_symbols = universe['symbol'].head(20).tolist() if not universe.empty else []\n",
    "    \n",
    "    if sample_symbols:\n",
    "        fundamental_data = storage.get_fundamental_data(sample_symbols)\n",
    "        \n",
    "        if not fundamental_data.empty:\n",
    "            # Analyze data completeness\n",
    "            completeness = (1 - fundamental_data.isnull().sum() / len(fundamental_data)) * 100\n",
    "            \n",
    "            # Filter to scoring-relevant columns\n",
    "            scoring_columns = ['pe_ratio', 'price_to_book', 'return_on_equity', \n",
    "                             'revenue_growth', 'earnings_growth', 'debt_to_equity']\n",
    "            \n",
    "            available_scoring_cols = [col for col in scoring_columns if col in completeness.index]\n",
    "            \n",
    "            if available_scoring_cols:\n",
    "                scoring_completeness = completeness[available_scoring_cols]\n",
    "                \n",
    "                print(\"\\nüìä Data Completeness for Scoring Factors:\")\n",
    "                for col, pct in scoring_completeness.items():\n",
    "                    status = \"‚úÖ\" if pct >= 80 else \"‚ö†Ô∏è\" if pct >= 50 else \"‚ùå\"\n",
    "                    print(f\"{status} {col}: {pct:.1f}%\")\n",
    "                \n",
    "                # Plot completeness\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                bars = plt.bar(range(len(scoring_completeness)), scoring_completeness.values)\n",
    "                plt.title('Data Completeness for Scoring Factors')\n",
    "                plt.xlabel('Factors')\n",
    "                plt.ylabel('Completeness (%)')\n",
    "                plt.xticks(range(len(scoring_completeness)), \n",
    "                          [col.replace('_', ' ').title() for col in scoring_completeness.index], \n",
    "                          rotation=45, ha='right')\n",
    "                plt.axhline(y=80, color='green', linestyle='--', alpha=0.7, label='Good (80%)')\n",
    "                plt.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='Acceptable (50%)')\n",
    "                plt.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(\"‚ùå No scoring factors found in fundamental data\")\n",
    "        else:\n",
    "            print(\"‚ùå No fundamental data available\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No symbols available for data quality check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connections\n",
    "if scorer:\n",
    "    scorer.close()\n",
    "    print(\"üîÑ Database connections closed\")\n",
    "\n",
    "print(\"\\n‚úÖ Scoring exploration completed!\")\n",
    "print(\"\\nüìù Next steps:\")\n",
    "print(\"1. Run the data pipeline to populate more data\")\n",
    "print(\"2. Adjust factor weights in config/factors.yml\")\n",
    "print(\"3. Test scoring on full universe\")\n",
    "print(\"4. Implement position sizing and risk management\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}